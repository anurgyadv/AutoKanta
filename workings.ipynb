{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying the sheets API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2 rows to ./processed_entries.csv\n",
      "[\n",
      "    {\n",
      "        \"1st entry or 2nd entry\": \"1st\",\n",
      "        \"Material\": \"Sand\",\n",
      "        \"Party Ref:\": \"Ozone city \",\n",
      "        \"Gross or Tare\": \"Gross\",\n",
      "        \"Save Bill\": \"Y\",\n",
      "        \"Print\": \"Y\",\n",
      "        \"Date\": \"2025-03-09\",\n",
      "        \"Time\": \"21:56:24\",\n",
      "        \"Cost\": \"250\",\n",
      "        \"Vehicle Type\": \"Dumper\"\n",
      "    },\n",
      "    {\n",
      "        \"1st entry or 2nd entry\": \"1st\",\n",
      "        \"Material\": \"Sand\",\n",
      "        \"Party Ref:\": \"\",\n",
      "        \"Gross or Tare\": \"Gross\",\n",
      "        \"Save Bill\": \"Y\",\n",
      "        \"Print\": \"Y\",\n",
      "        \"Date\": \"2025-03-14\",\n",
      "        \"Time\": \"10:21:23\",\n",
      "        \"Cost\": \"250\",\n",
      "        \"Vehicle Type\": \"Truck\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import logging\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from config import SPREADSHEET_ID, SHEET_NAME, API_KEY, LOCAL_CSV_PATH\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_sheet_data():\n",
    "    \"\"\"Fetch data from Google Sheets API\"\"\"\n",
    "    url = f'https://sheets.googleapis.com/v4/spreadsheets/{SPREADSHEET_ID}/values/{SHEET_NAME}!A1:Z?alt=json&key={API_KEY}'\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if 'values' not in data:\n",
    "            logger.warning(\"No data found in the sheet.\")\n",
    "            return []\n",
    "        \n",
    "        headers = data['values'][0]  # First row as headers\n",
    "        rows = data['values'][1:]  # Remaining rows as data\n",
    "\n",
    "        entries = [dict(zip(headers, row + [''] * (len(headers) - len(row)))) for row in rows]\n",
    "        return entries\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Error fetching data from Google Sheets: {e}\")\n",
    "        return []\n",
    "\n",
    "def split_vehicle_type(vehicle_type):\n",
    "    \"\"\"Split Vehicle Type into Cost and Vehicle Type\"\"\"\n",
    "    # Example: \"RMC TRUCK 250\" -> Cost = \"250\", Vehicle Type = \"RMC TRUCK\"\n",
    "    parts = vehicle_type.split()\n",
    "    if parts and parts[-1].isdigit():  # Check if the last part is a number\n",
    "        cost = parts[-1]\n",
    "        vehicle = ' '.join(parts[:-1])  # Join all parts except the last one\n",
    "        return cost, vehicle\n",
    "    return '', vehicle_type  # If no cost is found, return empty cost and original vehicle type\n",
    "\n",
    "def save_to_csv(entries):\n",
    "    \"\"\"Save formatted Google Sheets data to CSV\"\"\"\n",
    "    if not entries:\n",
    "        print(\"No data to save.\")\n",
    "        return\n",
    "\n",
    "    # Define field names (headers from the first entry)\n",
    "    fieldnames = list(entries[0].keys())\n",
    "\n",
    "    # Remove 'Timestamp' and 'Vehicle Type', and add 'Date', 'Time', 'Cost', and 'Vehicle Type'\n",
    "    if 'Timestamp' in fieldnames:\n",
    "        fieldnames.remove('Timestamp')\n",
    "    if 'Vehicle Type' in fieldnames:\n",
    "        fieldnames.remove('Vehicle Type')\n",
    "    fieldnames.extend(['Date', 'Time', 'Cost', 'Vehicle Type'])\n",
    "\n",
    "    # Check if file exists to avoid rewriting headers\n",
    "    file_exists = os.path.exists(LOCAL_CSV_PATH)\n",
    "\n",
    "    # Process entries to split Timestamp, Vehicle Type, and capitalize Yes/No answers\n",
    "    processed_entries = []\n",
    "    for entry in entries:\n",
    "        # Split the Timestamp into Date and Time\n",
    "        timestamp = entry.pop('Timestamp', '')\n",
    "        try:\n",
    "            dt = datetime.strptime(timestamp, '%m/%d/%Y %H:%M:%S')  # Adjust format to match your data\n",
    "            entry['Date'] = dt.strftime('%Y-%m-%d')\n",
    "            entry['Time'] = dt.strftime('%H:%M:%S')\n",
    "        except ValueError:\n",
    "            entry['Date'] = ''\n",
    "            entry['Time'] = ''\n",
    "\n",
    "        # Split Vehicle Type into Cost and Vehicle Type\n",
    "        vehicle_type = entry.pop('Vehicle Type', '')\n",
    "        cost, vehicle = split_vehicle_type(vehicle_type)\n",
    "        entry['Cost'] = cost\n",
    "        entry['Vehicle Type'] = vehicle\n",
    "\n",
    "        # Capitalize 'Yes' or 'No' answers\n",
    "        for key, value in entry.items():\n",
    "            if isinstance(value, str) and value.lower() in ['yes', 'no', 'y', 'n']:\n",
    "                entry[key] = value.upper()\n",
    "\n",
    "        processed_entries.append(entry)\n",
    "\n",
    "    with open(LOCAL_CSV_PATH, 'a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "\n",
    "        if not file_exists:\n",
    "            writer.writeheader()  # Write header only once\n",
    "\n",
    "        # Write data rows\n",
    "        writer.writerows(processed_entries)\n",
    "\n",
    "    print(f\"Saved {len(processed_entries)} rows to {LOCAL_CSV_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    entries = get_sheet_data()\n",
    "    save_to_csv(entries)\n",
    "    print(json.dumps(entries, indent=4))  # Print JSON for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying the email scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "b'[AUTHENTICATIONFAILED] Invalid credentials (Failure)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     mail\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minbox\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Connect to the inbox.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mail\n\u001b[1;32m---> 21\u001b[0m mail \u001b[38;5;241m=\u001b[39m connect_to_gmail_imap(EMAIL, PASSWORD)\n\u001b[0;32m     22\u001b[0m status, email_ids \u001b[38;5;241m=\u001b[39m mail\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(FROM \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{FROM_EMAIL}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m email_ids \u001b[38;5;241m=\u001b[39m email_ids[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit()\n",
      "Cell \u001b[1;32mIn[8], line 17\u001b[0m, in \u001b[0;36mconnect_to_gmail_imap\u001b[1;34m(user, password)\u001b[0m\n\u001b[0;32m     14\u001b[0m imap_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimap.gmail.com\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     16\u001b[0m mail \u001b[38;5;241m=\u001b[39m imaplib\u001b[38;5;241m.\u001b[39mIMAP4_SSL(imap_url)\n\u001b[1;32m---> 17\u001b[0m mail\u001b[38;5;241m.\u001b[39mlogin(user, password)\n\u001b[0;32m     18\u001b[0m mail\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minbox\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Connect to the inbox.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mail\n",
      "File \u001b[1;32mc:\\Users\\Anurag Yadav\\anaconda3\\Lib\\imaplib.py:612\u001b[0m, in \u001b[0;36mIMAP4.login\u001b[1;34m(self, user, password)\u001b[0m\n\u001b[0;32m    610\u001b[0m typ, dat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simple_command(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOGIN\u001b[39m\u001b[38;5;124m'\u001b[39m, user, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_quote(password))\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOK\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 612\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror(dat[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUTH\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typ, dat\n",
      "\u001b[1;31merror\u001b[0m: b'[AUTHENTICATIONFAILED] Invalid credentials (Failure)'"
     ]
    }
   ],
   "source": [
    "import imaplib\n",
    "import email\n",
    "import csv\n",
    "from config import USER_EMAIL, USER_PASSWORD, FROM_EMAIL\n",
    "\n",
    "# Email credentials\n",
    "EMAIL = USER_EMAIL\n",
    "PASSWORD = USER_PASSWORD\n",
    "IMAP_SERVER = \"imap.gmail.com\" \n",
    "\n",
    "import imaplib\n",
    "\n",
    "def connect_to_gmail_imap(user, password):\n",
    "    imap_url = 'imap.gmail.com'\n",
    "\n",
    "    mail = imaplib.IMAP4_SSL(imap_url)\n",
    "    mail.login(user, password)\n",
    "    mail.select('inbox')  # Connect to the inbox.\n",
    "    return mail\n",
    "\n",
    "mail = connect_to_gmail_imap(EMAIL, PASSWORD)\n",
    "status, email_ids = mail.search(None, '(FROM \"{FROM_EMAIL}\")')\n",
    "email_ids = email_ids[0].split()\n",
    "\n",
    "email_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['API_KEY', 'AUTOMATION_LOG', 'BOT_LOG', 'FROM_EMAIL', 'LOCAL_CSV_PATH', 'LOG_DIR', 'SHEET_NAME', 'SPREADSHEET_ID', 'USER_EMAIL', 'USER_PASSWORD', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import config\n",
    "print(dir(config))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping with .eml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Data:\n",
      "S.N: 004364\n",
      "Date & Time: 13.03.2025,07:58\n",
      "Vehicle Number (V.N): UPCT9086\n",
      "Vehicle Type (V.T): TRUCK\n",
      "Party (PRTY): N/A\n",
      "Material (MATR): COARSE SAND\n",
      "Charge (CHG1): 150\n",
      "Gross Weight (G/W): 37510\n",
      "Tare Weight (T/W): 11360\n",
      "Net Weight (N/W): 26150\n"
     ]
    }
   ],
   "source": [
    "import email\n",
    "import re\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "\n",
    "def extract_data_from_eml(file_path):\n",
    "    \"\"\"Extract structured data from a .eml file.\"\"\"\n",
    "    \n",
    "    # Open and parse the email file\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        msg = BytesParser(policy=policy.default).parse(f)\n",
    "    \n",
    "    # Get the email body\n",
    "    if msg.is_multipart():\n",
    "        body = \"\".join(part.get_payload(decode=True).decode(errors=\"ignore\") for part in msg.iter_parts() if part.get_content_type() == \"text/plain\")\n",
    "    else:\n",
    "        body = msg.get_payload(decode=True).decode(errors=\"ignore\")\n",
    "\n",
    "    # Regex pattern to extract required fields\n",
    "    pattern = re.compile(\n",
    "        r\"S\\.N:\\s*(\\d+).*?\"\n",
    "        r\"(\\d{2}\\.\\d{2}\\.\\d{4},\\d{2}:\\d{2}).*?\"\n",
    "        r\"V\\.N:\\s*([A-Z0-9]+).*?\"\n",
    "        r\"V\\.T:\\s*([A-Z]+).*?\"\n",
    "        r\"PRTY:\\s*(.*?)\\n.*?\"\n",
    "        r\"MATR:\\s*([A-Z\\s]+).*?\"\n",
    "        r\"CHG1:\\s*(\\d+).*?\"\n",
    "        r\"G/W:\\s*(\\d+).*?\"\n",
    "        r\"T/W:\\s*(\\d+).*?\"\n",
    "        r\"N/W:\\s*(\\d+)\",\n",
    "        re.DOTALL\n",
    "    )\n",
    "\n",
    "    # Extract data\n",
    "    match = pattern.search(body)\n",
    "    if match:\n",
    "        extracted_data = {\n",
    "            \"S.N\": match.group(1),\n",
    "            \"Date & Time\": match.group(2),\n",
    "            \"Vehicle Number (V.N)\": match.group(3),\n",
    "            \"Vehicle Type (V.T)\": match.group(4),\n",
    "            \"Party (PRTY)\": match.group(5).strip() if match.group(5).strip() else \"N/A\",\n",
    "            \"Material (MATR)\": match.group(6).strip(),\n",
    "            \"Charge (CHG1)\": match.group(7),\n",
    "            \"Gross Weight (G/W)\": match.group(8),\n",
    "            \"Tare Weight (T/W)\": match.group(9),\n",
    "            \"Net Weight (N/W)\": match.group(10),\n",
    "        }\n",
    "        return extracted_data\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example Usage\n",
    "file_path = \"email.eml\"  # Change this to your .eml file path\n",
    "data = extract_data_from_eml(file_path)\n",
    "\n",
    "if data:\n",
    "    print(\"Extracted Data:\")\n",
    "    for key, value in data.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"No matching data found in the email.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is BAF7-9770\n",
      "\n",
      " Directory of c:\\Users\\Anurag Yadav\\Documents\\Projects\\AutoK\n",
      "\n",
      "13/03/2025  11:14 AM    <DIR>          .\n",
      "10/03/2025  10:24 PM    <DIR>          ..\n",
      "13/03/2025  11:14 AM                22 .gitignore\n",
      "12/03/2025  10:05 PM               547 config.py\n",
      "13/03/2025  11:10 AM             5,620 email.eml\n",
      "12/03/2025  09:50 PM                 0 emailscraper.py\n",
      "09/03/2025  10:05 PM             1,785 keyboard_sequence.py\n",
      "09/03/2025  08:16 PM             7,169 LICENSE\n",
      "09/03/2025  10:05 PM               103 processed_entries.csv\n",
      "10/03/2025  10:25 PM               746 readme.md\n",
      "10/03/2025  10:24 PM             2,029 sheets_api.py\n",
      "10/03/2025  10:19 PM                 0 workings.ipynb\n",
      "12/03/2025  10:06 PM    <DIR>          __pycache__\n",
      "              10 File(s)         18,021 bytes\n",
      "               3 Dir(s)  430,697,472,000 bytes free\n"
     ]
    }
   ],
   "source": [
    "!cd ..\n",
    "!dir\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
